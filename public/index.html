<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Live Audio Transcription</title>
    <style>
      body {
        font-family: sans-serif;
        padding: 2rem;
        background: #f8f9fa;
        max-width: 800px;
        margin: 0 auto;
      }
      #transcript {
        white-space: pre-wrap;
        margin-top: 1rem;
        background: #fff;
        padding: 1.5rem;
        border-radius: 8px;
        font-size: 1.1rem;
        min-height: 200px;
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
        border: 1px solid #dee2e6;
      }
      button {
        padding: 0.8rem 1.5rem;
        font-size: 1rem;
        margin-right: 1rem;
        border: none;
        border-radius: 4px;
        cursor: pointer;
        transition: background-color 0.2s;
      }
      #startButton {
        background: #28a745;
        color: white;
      }
      #startButton:hover {
        background: #218838;
      }
      #stopButton {
        background: #dc3545;
        color: white;
      }
      #stopButton:hover {
        background: #c82333;
      }
      #refreshDevices {
        background: #6c757d;
        color: white;
      }
      #refreshDevices:hover {
        background: #5a6268;
      }
      button:disabled {
        background: #6c757d;
        cursor: not-allowed;
      }
      .status {
        margin: 1rem 0;
        padding: 0.8rem;
        border-radius: 4px;
        font-weight: 500;
      }
      .error {
        background: #ffebee;
        color: #c62828;
      }
      .success {
        background: #e8f5e9;
        color: #2e7d32;
      }
      .controls {
        margin: 1rem 0;
        padding: 1.5rem;
        background: #fff;
        border-radius: 8px;
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
      }
      select {
        padding: 0.8rem;
        margin: 0.5rem 0;
        width: 100%;
        max-width: 400px;
        border: 1px solid #ced4da;
        border-radius: 4px;
        font-size: 1rem;
      }
      .recording-indicator {
        display: none;
        margin: 1rem 0;
        padding: 0.5rem;
        background: #dc3545;
        color: white;
        border-radius: 4px;
        text-align: center;
        animation: pulse 1.5s infinite;
      }
      @keyframes pulse {
        0% {
          opacity: 1;
        }
        50% {
          opacity: 0.5;
        }
        100% {
          opacity: 1;
        }
      }
    </style>
  </head>
  <body>
    <h1>Live Audio Transcription</h1>
    <div class="controls">
      <div id="micControls">
        <select id="deviceSelect">
          <option value="">Select audio input device...</option>
        </select>
      </div>
    </div>
    <div id="status" class="status">Waiting to connect...</div>
    <div id="recordingIndicator" class="recording-indicator">Recording...</div>
    <button id="startButton">Start Transcription</button>
    <button id="stopButton" disabled>Stop</button>
    <div id="transcript">Waiting for audio...</div>

    <script>
      let socket;
      let audioContext;
      let source;
      let processor;
      let mediaStream;

      // Populate audio input devices
      async function populateDeviceList() {
        try {
          console.log("Starting device enumeration...");

          // First request microphone permission
          console.log("Requesting microphone permission...");
          const stream = await navigator.mediaDevices.getUserMedia({
            audio: true,
          });
          console.log("Microphone permission granted");

          // Stop the temporary stream
          stream.getTracks().forEach((track) => track.stop());

          // Now enumerate devices
          console.log("Enumerating devices...");
          const devices = await navigator.mediaDevices.enumerateDevices();
          console.log("All devices:", devices);

          const audioInputs = devices.filter(
            (device) => device.kind === "audioinput"
          );
          console.log("Audio input devices:", audioInputs);

          const select = document.getElementById("deviceSelect");

          // Clear existing options
          select.innerHTML =
            '<option value="">Select audio input device...</option>';

          audioInputs.forEach((device) => {
            console.log("Adding device:", device.label, device.deviceId);
            const option = document.createElement("option");
            option.value = device.deviceId;
            option.text = device.label || `Microphone ${select.length}`;
            select.appendChild(option);
          });

          if (audioInputs.length === 0) {
            console.log("No audio input devices found");
            updateStatus("No audio input devices found", true);
          } else {
            console.log(`Found ${audioInputs.length} audio input devices`);
            updateStatus(`Found ${audioInputs.length} audio input devices`);
          }
        } catch (error) {
          console.error("Error accessing microphone:", error);
          updateStatus("Error accessing microphone: " + error.message, true);
        }
      }

      // Add a button to manually refresh devices
      document.body.insertAdjacentHTML(
        "afterbegin",
        `
        <button id="refreshDevices" style="margin-bottom: 1rem;">Refresh Microphone List</button>
      `
      );

      document.getElementById("refreshDevices").onclick = async () => {
        console.log("Manually refreshing device list...");
        await populateDeviceList();
      };

      // Call this when the page loads
      document.getElementById("startButton").onclick = async () => {
        try {
          // First populate devices if not already done
          if (document.getElementById("deviceSelect").options.length <= 1) {
            await populateDeviceList();
          }

          socket = new WebSocket("ws://localhost:3001");

          socket.onopen = () => {
            updateStatus("Connected to server");
            // Request to start audio stream
            socket.send(
              JSON.stringify({
                type: "start_stream",
              })
            );
          };

          socket.onmessage = async (event) => {
            const message = JSON.parse(event.data);
            console.log("Received from server:", message);

            switch (message.type) {
              case "stream_started":
                updateStatus("Audio stream started");
                try {
                  await startMicrophoneCapture();
                  document.getElementById("recordingIndicator").style.display =
                    "block";
                } catch (error) {
                  updateStatus(error.message, true);
                  socket.close();
                  return;
                }

                document.getElementById("startButton").disabled = true;
                document.getElementById("stopButton").disabled = false;
                document.getElementById("deviceSelect").disabled = true;
                break;

              case "transcription":
                console.log("Transcription received:", message.text);
                const transcript = document.getElementById("transcript");
                if (transcript.textContent === "Waiting for audio...") {
                  transcript.textContent = message.text;
                } else {
                  transcript.textContent += " " + message.text;
                }
                break;

              case "error":
                updateStatus(message.message, true);
                break;
            }
          };

          socket.onerror = (error) => {
            updateStatus("WebSocket error: " + error.message, true);
          };

          socket.onclose = () => {
            stopMicrophoneCapture();
            updateStatus("Disconnected from server");
            document.getElementById("recordingIndicator").style.display =
              "none";
            document.getElementById("startButton").disabled = false;
            document.getElementById("stopButton").disabled = true;
            document.getElementById("deviceSelect").disabled = false;
          };
        } catch (error) {
          updateStatus("Error: " + error.message, true);
        }
      };

      document.getElementById("stopButton").onclick = () => {
        if (socket && socket.readyState === WebSocket.OPEN) {
          socket.send(JSON.stringify({ type: "stop_stream" }));
        }
        stopMicrophoneCapture();
        if (socket) {
          socket.close();
        }
      };

      function updateStatus(message, isError = false) {
        const status = document.getElementById("status");
        status.textContent = message;
        status.className = `status ${isError ? "error" : "success"}`;
      }

      async function startMicrophoneCapture() {
        try {
          const deviceId = document.getElementById("deviceSelect").value;
          if (!deviceId) {
            throw new Error("Please select an audio input device");
          }

          mediaStream = await navigator.mediaDevices.getUserMedia({
            audio: {
              deviceId: deviceId,
              sampleRate: 16000,
              channelCount: 1,
              echoCancellation: true,
              noiseSuppression: true,
            },
          });

          audioContext = new AudioContext({
            sampleRate: 16000,
          });
          source = audioContext.createMediaStreamSource(mediaStream);
          processor = audioContext.createScriptProcessor(4096, 1, 1);

          processor.onaudioprocess = (e) => {
            if (socket && socket.readyState === WebSocket.OPEN) {
              const inputData = e.inputBuffer.getChannelData(0);
              // Convert Float32Array to Int16Array
              const pcmData = new Int16Array(inputData.length);
              for (let i = 0; i < inputData.length; i++) {
                pcmData[i] = Math.max(-1, Math.min(1, inputData[i])) * 0x7fff;
              }
              socket.send(
                JSON.stringify({
                  type: "audio_data",
                  data: Array.from(pcmData),
                })
              );
            }
          };

          source.connect(processor);
          processor.connect(audioContext.destination);
        } catch (error) {
          console.error("Error starting microphone capture:", error);
          throw error;
        }
      }

      function stopMicrophoneCapture() {
        if (processor) {
          processor.disconnect();
          processor = null;
        }
        if (source) {
          source.disconnect();
          source = null;
        }
        if (mediaStream) {
          mediaStream.getTracks().forEach((track) => track.stop());
          mediaStream = null;
        }
        if (audioContext) {
          audioContext.close();
          audioContext = null;
        }
      }
    </script>
  </body>
</html>
